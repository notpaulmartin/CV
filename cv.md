# Paul Martin


<div class="head">

- PhD Student
- Language Technology Lab
- University of Cambridge

</div>

<div class="profile">
<!-- TODO: add info about computational neuro / comp' molecular bio -->
I am a PhD student in the Language Technology Lab at the University of Cambridge, focusing on <b>Modular and Efficient Deep Learning for NLP</b> under supervision by Ivan Vulić and Edoardo Ponti.
<br><br>
Previously, I obtained my Master of Informatics (MInf) in 2024 from the University of Edinburgh, where I worked on Distributed Training and Cross-Architecture Knowledge Distillation, supervised by Hao Tang.
<!-- Outside of academia, I find inspiration in photography, long-distance running, and hiking in the Scottish Highlands. -->
</div>

<article>

<section class="left">

## Contact
- [pm844@cam.ac.uk](mailto:pm844@cam.ac.uk)
- +44 (0) 7785 296197

## Website
- [PaulsBitsAndBytes.com](https://PaulsBitsAndBytes.com)

## Awards
- 80% thesis mark
- 77% degree average

## Research Interests
- Modular Deep Learning
- Efficient, Distributed Training & Inference
- Natural Language Processing


## Other Interests
- Photography
- Long-Distance Running
- Hiking in the Scottish Highlands

## Languages
- English (native)
- German (native)
- Spanish (learning)

<!-- TODO: Awards section -->

</section>


<section class="right">

## Education

### PhD at the Language Technology Lab
#### University of Cambridge (2024 - 2028)
- Researching modular architectures to improve the efficiency of deep learning models
- Supervised by Ivan Vulić and Edoardo Ponti

### MInf Informatics
#### University of Edinburgh (2019 - 2024)
- Specializing in Deep Learning and conducting research on distributed optimisation of neural networks for my Master’s Thesis
- Achieved an outstanding 80% in my Bachelor's Thesis and 77% overall

### Exchange Year
#### University of Hong Kong (2021 - 2022)
- Selected for my first choice destination out of 800+ applicants.
- Relevant topics: Machine Learning, AI Project, Computer Vision, Big data
<!-- TODO: list relevant topics/courses -->
<!-- - Engaged in a diverse set of coursework expanding computational and international perspectives -->


## Experience

### Teaching Assistant for Machine Learning
#### The University of Edinburgh (AY 2023/24)
- Guiding students in Machine Learning through in-person and online assistance, providing clarifications on theory and applications.
<!-- TODO: more technical info -->

### Research Assistant Intern
#### With Kartic Subr, The University of Edinburgh (Summer 2023)
- Led research on using Graph Neural Networks for spectral coarsening of 3D meshes.
- Trained models on approximate gradients from physics simulations.
<!-- - Plans to submit a paper later this year, or early 2024. -->

### Tutor for Machine Learning
#### The University of Edinburgh (AY 2022/23)
- Led a series of workshops for a Machine Learning course, supporting 3rd and 4th-year informatics students in their studies of ML techniques.

### ML Intern for Natural Language Processing
#### Migrasia Global Solutions (Sep - Dec 2021)
- Developed NLP tools to combat forced labour among refugees and migrant workers in Hong Kong.
- Engineered a multilingual sentiment analysis tool and topic classifier for Facebook messages, and investigated biases in Hong Kong's judiciary by processing judgements at scale.

<!-- ### Founder and CEO
#### build-yours.de (2017 - 2019)
- Co-founded and propelled a tech start-up to profitability, offering DIY home accessory kits. I managed all facets from product engineering to international supply chain, before transitioning to academic pursuits

### Advanced Mathematics Teacher (Extracurricular)
#### Mathematik in Bremen! e.V. (2015 - 2019)
- Developed and delivered enriching mathematics content for 12-16 year-old students through an engaging flipped-classroom teaching style, exploring topics beyond the standard curriculum -->

</section>

</article>

## Research Projects
#### [For more research projects, visit my website](https://PaulsBitsAndBytes.com)

### Master's Thesis: Distributed Optimisation of Deep Neural Networks  <span class="status">2023/2024</span>
Researching optimisers for the distributed training of deep neural networks, contributing to the field of scalable, efficient neural network training.


### Bachelor’s Thesis: Cross-Architecture Knowledge Distillation for Automatic Speech Recognition  <span class="status">2022/23</span>
Achieved an **80% mark** developing knowledge distillation techniques for models with mismatched output dimensions, providing insights into effective model compression strategies and architecture trade-offs.

### Spectral Coarsening using GNNs  <span class="status">Aug 2023</span>
Explored the application of Graph Neural Networks to accelerate parameter set determination for 3D meshes, enhancing subsequent physics simulations' efficiency. During a research internship with Kartic Subr.

<!-- TODO: Worked with Loss function with unknown derivative -->

### Review of a Biologically Inspired Neural Network to Model PTSD and Eye Movement Desensitisation Reprocessing Therapy  <span class="status">Apr 2023</span>
Coursework in Computational Cognitive Neuroscience, taught by Peggy Seriès. Achieved an 80% mark.


<!-- ### Predicting Pollution in Krakow
#### Using temperature and precipitation-forecasts to accurately predict pollution in Krakow, Poland several days ahead, to generate weather warnings. -->

<!-- ### Markdown-parser written in Go
#### Used to build this CV -->


<!-- ### Investigating Biases in the Hong Kong Judiciary
#### Quantifying the racial bias by using Data Science techniques to process 4,743 transcripts of court hearings between 2014 and 2021. -->

<!-- ### Intuitive approximation for teaching and understanding PCA
#### Created a more approachable algorithm for Principal Component Analysis by reworking the initial explanation taught to me -->

<!-- ### Investigation into Bayesian Networks with Haskell
#### Developed software to efficiently represent and calculate with interdependent Probabilistic Random Variables -->
